"""
OpenAI Assistant æ§åˆ¶å™¨
å¤„ç†åŸºäº OpenAI Assistant API çš„èŠå¤©åŠŸèƒ½
"""
import os
import tempfile
import time
import json
import threading
from functools import wraps
from flask import jsonify, request, current_app, Response, stream_with_context

# å¯¼å…¥ OpenAI Assistant ç›¸å…³åº“
import openai
from libs import openai_assistant
from services.openai_service import OpenAIService

# åˆå§‹åŒ–æœåŠ¡
openai_service = OpenAIService()

# ç”¨äºå­˜å‚¨ç”¨æˆ·çº¿ç¨‹IDçš„å­—å…¸
# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™åº”è¯¥å­˜å‚¨åœ¨æ•°æ®åº“ä¸­
user_threads = {}

def init_assistant_thread():
    """åˆå§‹åŒ– Assistant çº¿ç¨‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    try:
        # è·å–å½“å‰ä¼šè¯ IDï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™åº”è¯¥æ˜¯ç”¨æˆ·ç‰¹å®šçš„ï¼‰
        session_id = request.cookies.get('session_id', 'default_user')

        # å¦‚æœçº¿ç¨‹ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çº¿ç¨‹
        if session_id not in user_threads:
            client = openai.OpenAI()
            thread = client.beta.threads.create()
            user_threads[session_id] = thread.id
            print(f"å·²ä¸ºç”¨æˆ· {session_id} åˆ›å»ºæ–°çº¿ç¨‹: {thread.id}")

        return user_threads[session_id]

    except Exception as e:
        print(f"åˆå§‹åŒ–çº¿ç¨‹é”™è¯¯: {str(e)}")
        raise

# è¾…åŠ©å‡½æ•° - åˆ›å»ºSSEæ ¼å¼çš„æ¶ˆæ¯
def format_sse(event, data):
    """
    æ ¼å¼åŒ–ç”¨äºæœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆSSEï¼‰çš„æ¶ˆæ¯

    å‚æ•°:
        event: äº‹ä»¶åç§°
        data: äº‹ä»¶æ•°æ®ï¼ˆå°†è¢«è½¬æ¢ä¸ºJSONï¼‰

    è¿”å›:
        æ ¼å¼åŒ–çš„SSEæ¶ˆæ¯å­—ç¬¦ä¸²
    """
    return f"event: {event}\ndata: {json.dumps(data)}\n\n"


def assistant_chat_stream():
    """ä½¿ç”¨æœåŠ¡å™¨å‘é€äº‹ä»¶ï¼ˆSSEï¼‰å¤„ç†åŸºäº Assistant API çš„æµå¼èŠå¤©è¯·æ±‚"""
    # è·å–æ¶ˆæ¯å†…å®¹
    message = request.args.get('message')
    if not message:
        return jsonify({"error": "Message content missing"}), 400

    # è·å–ç”¨æˆ·è¯­è¨€ï¼ˆå¦‚æœä¼ å…¥ï¼‰
    lang = request.args.get('language', 'en')

    # å†…å®¹å®¡æ ¸
    is_flagged, categories = openai_service.moderate_content(message)
    print(f"æ˜¯å¦è¢«æ ‡è®°: {is_flagged}, ç±»åˆ«: {categories}")

    # åˆå§‹åŒ–æˆ–è·å–ç”¨æˆ·çš„çº¿ç¨‹ID
    try:
        thread_id = init_assistant_thread()
    except Exception as e:
        return jsonify({"error": str(e)}), 500

    def generate():
        # å‘é€åˆå§‹çŠ¶æ€
        yield format_sse("status", {"status": "Analyzing your request..."})

        try:
            # æ£€æŸ¥å†…å®¹æ˜¯å¦è¢«æ ‡è®°ä¸ºä¸é€‚å½“
            if is_flagged:
                yield format_sse("status", {"status": "Content moderation check..."})

                # åŠ¨æ€ç”Ÿæˆå‹å¥½çš„è­¦å‘Šä¿¡æ¯
                context = []  # æµå¼æ¨¡å¼ä¸‹ä¸éœ€è¦å¯¹è¯ä¸Šä¸‹æ–‡
                warning_message = openai_service.generate_friendly_warning(categories, lang, context)

                # æ„å»ºè­¦å‘Šå“åº”
                response = {
                    "text": warning_message,
                    "is_warning": True
                }

                # ç›´æ¥è¿”å›è­¦å‘Šï¼Œä¸ç»§ç»­å¤„ç†è¯·æ±‚
                yield format_sse("complete", response)
                return

            # å†…å®¹å®¡æ ¸é€šè¿‡ï¼Œç»§ç»­æ­£å¸¸å¤„ç†
            client = openai.OpenAI()

            # è·å–å½“å‰ Assistant ID
            assistant_id = os.getenv('OPENAI_ASSISTANT_ID', None)
            if not assistant_id:
                assistant_id = current_app.config.get('OPENAI_ASSISTANT_ID')
                if not assistant_id:
                    yield format_sse("error", {"error": "Assistant ID not configured"})
                    return

            # å‘çº¿ç¨‹æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=message
            )

            yield format_sse("status", {"status": "Thinking..."})

            # è¿è¡ŒåŠ©æ‰‹
            run = client.beta.threads.runs.create(
                thread_id=thread_id,
                assistant_id=assistant_id,
            )

            # åˆå§‹åŒ–å‡½æ•°è°ƒç”¨ç»“æœ
            function_results = []

            # ç­‰å¾…è¿è¡Œå®Œæˆ
            while True:
                run_status = client.beta.threads.runs.retrieve(
                    thread_id=thread_id,
                    run_id=run.id
                )

                # å‘é€å½“å‰çŠ¶æ€æ›´æ–°
                yield format_sse("status", {"status": f"Assistant status: {run_status.status}"})

                if run_status.status == 'completed':
                    yield format_sse("status", {"status": "Generating response..."})
                    break

                elif run_status.status == 'requires_action':
                    yield format_sse("status", {"status": "Executing function call..."})

                    # å¤„ç†å‡½æ•°è°ƒç”¨è¯·æ±‚
                    if run_status.required_action.type == "submit_tool_outputs":
                        tool_calls = run_status.required_action.submit_tool_outputs.tool_calls
                        tool_outputs = []

                        for tool_call in tool_calls:
                            function_name = tool_call.function.name
                            function_args = json.loads(tool_call.function.arguments)

                            # è®°å½•å‡½æ•°è°ƒç”¨
                            function_results.append({
                                "name": function_name,
                                "arguments": function_args
                            })

                            yield format_sse("status", {"status": f"Calling function: {function_name}"})

                            # æ ¹æ®å‡½æ•°åç§°å¤„ç†ä¸åŒçš„å‡½æ•°è°ƒç”¨
                            if function_name == "recommend_books":
                                yield format_sse("progress", {
                                    "status": "Analyzing reading interests and recommending books...",
                                    "progress": {
                                        "type": "book_recommendation",
                                        "icon": "ğŸ“š"
                                    }
                                })

                                # å¤„ç†å›¾ä¹¦æ¨èå‡½æ•°è°ƒç”¨
                                user_interests = function_args.get("user_interests", "")

                                # è·å–ä¹¦ç±æ¨èåŠ©æ‰‹ ID
                                book_recommandation_assistant_id = current_app.config.get('BOOK_RECOMMANDATION_ASSISTANT_ID')
                                if not book_recommandation_assistant_id:
                                    yield format_sse("status", {"status": "Book recommendation assistant ID not configured, cannot provide book recommendations"})
                                    recommended_books = []
                                else:
                                    # è°ƒç”¨ search_books_by_interest è·å–æ¨èä¹¦ç±
                                    from libs import openai_assistant as oa
                                    recommended_books = oa.search_books_by_interest(
                                        book_recommandation_assistant_id,
                                        user_interests
                                    )

                                    yield format_sse("status", {"status": "Found matching book recommendations"})

                                # è®°å½•å‡½æ•°è°ƒç”¨ç»“æœ
                                function_results[-1]["result"] = recommended_books

                                # è¿”å›æ¨èä¹¦ç±ç»™å¯¹è¯åŠ©æ‰‹
                                tool_outputs.append({
                                    "tool_call_id": tool_call.id,
                                    "output": json.dumps({
                                        "status": "success",
                                        "recommended_books": recommended_books
                                    })
                                })

                            elif function_name == "search_book_by_title":
                                yield format_sse("progress", {
                                    "status": "Searching for books matching the title...",
                                    "progress": {
                                        "type": "book_search",
                                        "icon": "ğŸ”"
                                    }
                                })

                                # å¤„ç†æ ¹æ®ä¹¦åæœç´¢å›¾ä¹¦å‡½æ•°è°ƒç”¨
                                title = function_args.get("title", "")

                                # è·å–ä¹¦ç±æ¨èåŠ©æ‰‹ IDæ¥è·å–å…³è”çš„vector_store_id
                                book_recommandation_assistant_id = current_app.config.get('BOOK_RECOMMANDATION_ASSISTANT_ID')
                                if not book_recommandation_assistant_id:
                                    yield format_sse("status", {"status": "Book recommendation assistant ID not configured, cannot search for books"})
                                    matched_books = []
                                else:
                                    # è·å–åŠ©æ‰‹è¯¦æƒ…ä»¥è·å–vector_store_id
                                    from libs import openai_assistant as oa
                                    client = openai.OpenAI()
                                    assistant = client.beta.assistants.retrieve(book_recommandation_assistant_id)

                                    if assistant.tool_resources and assistant.tool_resources.file_search:
                                        vector_store_ids = assistant.tool_resources.file_search.vector_store_ids
                                        if vector_store_ids:
                                            vector_store_id = vector_store_ids[0]
                                            yield format_sse("status", {"status": f"Searching for title using vector_store: {title}"})
                                            matched_books = oa.search_book_by_title(vector_store_id, title)

                                            if matched_books:
                                                yield format_sse("status", {"status": f"Found {len(matched_books)} matching books"})
                                            else:
                                                yield format_sse("status", {"status": "No matching books found"})
                                        else:
                                            yield format_sse("status", {"status": "No associated vector_store found"})
                                            matched_books = []
                                    else:
                                        yield format_sse("status", {"status": "Assistant not configured with file_search tool"})
                                        matched_books = []

                                # è®°å½•å‡½æ•°è°ƒç”¨ç»“æœ
                                function_results[-1]["result"] = matched_books

                                # è¿”å›åŒ¹é…çš„å›¾ä¹¦ç»™å¯¹è¯åŠ©æ‰‹
                                tool_outputs.append({
                                    "tool_call_id": tool_call.id,
                                    "output": json.dumps({
                                        "status": "success",
                                        "matched_books": matched_books
                                    })
                                })

                            elif function_name == "get_book_content":
                                yield format_sse("progress", {
                                    "status": "Retrieving book content...",
                                    "progress": {
                                        "type": "book_content",
                                        "icon": "ğŸ“–"
                                    }
                                })

                                # å¤„ç†è·å–å›¾ä¹¦å†…å®¹å‡½æ•°è°ƒç”¨
                                book_id = function_args.get("book_id", "")

                                # è°ƒç”¨data_sourceè·å–å›¾ä¹¦å†…å®¹
                                from libs import openai_assistant as oa
                                book_data = oa.get_book_content(book_id)

                                # è®°å½•å‡½æ•°è°ƒç”¨ç»“æœ
                                if book_data:
                                    yield format_sse("status", {"status": f"Successfully retrieved content for '{book_data['book_title']}'"})
                                    function_results[-1]["result"] = {
                                        "book_id": book_data["book_id"],
                                        "book_title": book_data["book_title"],
                                        "status": "success"
                                    }
                                else:
                                    yield format_sse("status", {"status": f"Book with ID {book_id} not found"})
                                    function_results[-1]["result"] = {
                                        "book_id": book_id,
                                        "status": "not_found"
                                    }

                                # è¿”å›å›¾ä¹¦å†…å®¹ç»™å¯¹è¯åŠ©æ‰‹
                                tool_outputs.append({
                                    "tool_call_id": tool_call.id,
                                    "output": json.dumps({
                                        "status": "success" if book_data else "not_found",
                                        "book": book_data
                                    })
                                })

                        # æäº¤å‡½æ•°æ‰§è¡Œç»“æœç»™ OpenAI
                        client.beta.threads.runs.submit_tool_outputs(
                            thread_id=thread_id,
                            run_id=run.id,
                            tool_outputs=tool_outputs
                        )

                elif run_status.status in ['failed', 'cancelled', 'expired']:
                    yield format_sse("error", {"error": f"Assistant run failed: {run_status.status}"})
                    return

                # çŸ­æš‚ç­‰å¾…åå†æ£€æŸ¥çŠ¶æ€
                time.sleep(0.5)

            # è·å–æœ€æ–°çš„åŠ©æ‰‹å›å¤
            messages = client.beta.threads.messages.list(thread_id=thread_id)

            # è·å–æœ€æ–°çš„åŠ©æ‰‹å›å¤ï¼ˆç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯æœ€æ–°çš„ï¼‰
            assistant_message = None
            for msg in messages.data:
                if msg.role == "assistant":
                    assistant_message = msg
                    break

            if not assistant_message:
                yield format_sse("error", {"error": "No response received from assistant"})
                return

            # æå–æ–‡æœ¬å†…å®¹
            ai_response = ""
            for content in assistant_message.content:
                if content.type == "text":
                    if content.text.annotations:
                        print(content.text.annotations)
                    # ä½¿ç”¨ openai_assistant æ¨¡å—ä¸­çš„ clean_text å‡½æ•°æ¸…ç†æ–‡æœ¬
                    ai_response += openai_assistant.clean_text(content.text.value)

            # ç”Ÿæˆè¯­éŸ³
            yield format_sse("status", {"status": "Generating voice response..."})
            audio_data = openai_service.text_to_speech(ai_response)

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜éŸ³é¢‘
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as temp_file:
                temp_file.write(audio_data)
                audio_path = temp_file.name

            # æ„å»ºå“åº”
            response = {
                "text": ai_response,
                "audio_url": f"/api/audio/{os.path.basename(audio_path)}",
                "function_results": function_results
            }

            # ä¿å­˜æ–‡ä»¶è·¯å¾„ä»¥ä¾¿åç»­è¯·æ±‚
            current_app.config[f"TEMP_AUDIO_{os.path.basename(audio_path)}"] = audio_path

            # å‘é€å®Œæˆäº‹ä»¶
            yield format_sse("complete", response)

        except Exception as e:
            yield format_sse("error", {"error": str(e)})

    return Response(stream_with_context(generate()), content_type="text/event-stream")


def assistant_chat():
    """å¤„ç†åŸºäº Assistant API çš„å¸¸è§„èŠå¤©è¯·æ±‚"""
    try:
        data = request.json
        if not data or 'message' not in data:
            return jsonify({"error": "Message content missing"}), 400

        user_message = data['message']

        # è·å–ç”¨æˆ·è¯­è¨€ï¼ˆå¦‚æœä¼ å…¥ï¼‰
        lang = data.get('language', 'en')

        # å†…å®¹å®¡æ ¸
        is_flagged, categories = openai_service.moderate_content(user_message)
        print(f"æ˜¯å¦è¢«æ ‡è®°: {is_flagged}, ç±»åˆ«: {categories}")

        # æ£€æŸ¥å†…å®¹æ˜¯å¦è¢«æ ‡è®°ä¸ºä¸é€‚å½“
        if is_flagged:
            # åŠ¨æ€ç”Ÿæˆå‹å¥½çš„è­¦å‘Šä¿¡æ¯
            context = []  # éæµå¼æ¨¡å¼ä¸‹æš‚ä¸ä½¿ç”¨å¯¹è¯ä¸Šä¸‹æ–‡
            warning_message = openai_service.generate_friendly_warning(categories, lang, context)

            # æ„å»ºè­¦å‘Šå“åº”å¹¶ç›´æ¥è¿”å›
            return jsonify({
                "text": warning_message,
                "is_warning": True
            })

        # å†…å®¹å®¡æ ¸é€šè¿‡ï¼Œç»§ç»­æ­£å¸¸å¤„ç†
        # åˆå§‹åŒ–æˆ–è·å–ç”¨æˆ·çš„çº¿ç¨‹ID
        thread_id = init_assistant_thread()

        client = openai.OpenAI()

        # è·å–å½“å‰ Assistant ID
        assistant_id = os.getenv('OPENAI_ASSISTANT_ID', None)
        if not assistant_id:
            # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰è®¾ç½®ï¼Œå°è¯•ä»åº”ç”¨é…ç½®ä¸­è·å–
            assistant_id = current_app.config.get('OPENAI_ASSISTANT_ID')
            if not assistant_id:
                return jsonify({"error": "Assistant ID not configured"}), 500

        # å‘çº¿ç¨‹æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=user_message
        )

        # è¿è¡ŒåŠ©æ‰‹
        run = client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=assistant_id,
        )

        # åˆå§‹åŒ–å‡½æ•°è°ƒç”¨ç»“æœ
        function_results = []

        # ç­‰å¾…è¿è¡Œå®Œæˆ
        while True:
            run_status = client.beta.threads.runs.retrieve(
                thread_id=thread_id,
                run_id=run.id
            )
            print(f"Assistant è¿è¡ŒçŠ¶æ€: {run_status.status}")

            if run_status.status == 'completed':
                break
            elif run_status.status == 'requires_action':
                print("Assistant éœ€è¦æ‰§è¡Œå‡½æ•°")
                # å¤„ç†å‡½æ•°è°ƒç”¨è¯·æ±‚
                if run_status.required_action.type == "submit_tool_outputs":
                    tool_calls = run_status.required_action.submit_tool_outputs.tool_calls
                    tool_outputs = []

                    for tool_call in tool_calls:
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)
                        print(f"å‡½æ•°åç§°: {function_name}")
                        print(f"å‡½æ•°å‚æ•°: {function_args}")

                        # è®°å½•å‡½æ•°è°ƒç”¨
                        function_results.append({
                            "name": function_name,
                            "arguments": function_args
                        })

                        # æ ¹æ®å‡½æ•°åç§°å¤„ç†ä¸åŒçš„å‡½æ•°è°ƒç”¨
                        if function_name == "recommend_books":
                            # å¤„ç†å›¾ä¹¦æ¨èå‡½æ•°è°ƒç”¨
                            user_interests = function_args.get("user_interests", "")
                            print(f"ç”¨æˆ·å…´è¶£: {user_interests}")

                            # è·å–ä¹¦ç±æ¨èåŠ©æ‰‹ ID
                            book_recommandation_assistant_id = current_app.config.get('BOOK_RECOMMANDATION_ASSISTANT_ID')
                            if not book_recommandation_assistant_id:
                                print("æœªé…ç½®ä¹¦ç±æ¨èåŠ©æ‰‹ IDï¼Œæ— æ³•æä¾›å›¾ä¹¦æ¨è")
                                recommended_books = []
                            else:
                                # è°ƒç”¨ search_books_by_interest è·å–æ¨èä¹¦ç±
                                print(f"è°ƒç”¨ä¹¦ç±æ¨èåŠ©æ‰‹ ID: {book_recommandation_assistant_id}")
                                from libs import openai_assistant as oa
                                recommended_books = oa.search_books_by_interest(
                                    book_recommandation_assistant_id,
                                    user_interests
                                )

                            # è®°å½•å‡½æ•°è°ƒç”¨ç»“æœ
                            function_results[-1]["result"] = recommended_books

                            # è¿”å›æ¨èä¹¦ç±ç»™å¯¹è¯åŠ©æ‰‹
                            tool_outputs.append({
                                "tool_call_id": tool_call.id,
                                "output": json.dumps({
                                    "status": "success",
                                    "recommended_books": recommended_books
                                })
                            })

                        elif function_name == "search_book_by_title":
                            # å¤„ç†æ ¹æ®ä¹¦åæœç´¢å›¾ä¹¦å‡½æ•°è°ƒç”¨
                            title = function_args.get("title", "")
                            print(f"æœç´¢ä¹¦å: {title}")

                            # è·å–ä¹¦ç±æ¨èåŠ©æ‰‹ IDæ¥è·å–å…³è”çš„vector_store_id
                            book_recommandation_assistant_id = current_app.config.get('BOOK_RECOMMANDATION_ASSISTANT_ID')
                            if not book_recommandation_assistant_id:
                                print("æœªé…ç½®ä¹¦ç±æ¨èåŠ©æ‰‹ IDï¼Œæ— æ³•æœç´¢å›¾ä¹¦")
                                matched_books = []
                            else:
                                # è·å–åŠ©æ‰‹è¯¦æƒ…ä»¥è·å–vector_store_id
                                from libs import openai_assistant as oa
                                client = openai.OpenAI()
                                assistant = client.beta.assistants.retrieve(book_recommandation_assistant_id)

                                if assistant.tool_resources and assistant.tool_resources.file_search:
                                    vector_store_ids = assistant.tool_resources.file_search.vector_store_ids
                                    if vector_store_ids:
                                        vector_store_id = vector_store_ids[0]
                                        print(f"ä½¿ç”¨vector_store_id: {vector_store_id}æœç´¢ä¹¦ç±")
                                        matched_books = oa.search_book_by_title(vector_store_id, title)
                                    else:
                                        print("æœªæ‰¾åˆ°å…³è”çš„vector_store")
                                        matched_books = []
                                else:
                                    print("åŠ©æ‰‹æœªé…ç½®file_searchå·¥å…·")
                                    matched_books = []

                            # è®°å½•å‡½æ•°è°ƒç”¨ç»“æœ
                            function_results[-1]["result"] = matched_books

                            # è¿”å›åŒ¹é…çš„å›¾ä¹¦ç»™å¯¹è¯åŠ©æ‰‹
                            tool_outputs.append({
                                "tool_call_id": tool_call.id,
                                "output": json.dumps({
                                    "status": "success",
                                    "matched_books": matched_books
                                })
                            })

                        elif function_name == "get_book_content":
                            # å¤„ç†è·å–å›¾ä¹¦å†…å®¹å‡½æ•°è°ƒç”¨
                            book_id = function_args.get("book_id", "")
                            print(f"è·å–å›¾ä¹¦å†…å®¹ï¼Œbook_id: {book_id}")

                            # è°ƒç”¨data_sourceè·å–å›¾ä¹¦å†…å®¹
                            from libs import openai_assistant as oa
                            book_data = oa.get_book_content(book_id)

                            # è®°å½•å‡½æ•°è°ƒç”¨ç»“æœ
                            if book_data:
                                function_results[-1]["result"] = {
                                    "book_id": book_data["book_id"],
                                    "book_title": book_data["book_title"],
                                    "status": "success"
                                }
                            else:
                                function_results[-1]["result"] = {
                                    "book_id": book_id,
                                    "status": "not_found"
                                }

                            # è¿”å›å›¾ä¹¦å†…å®¹ç»™å¯¹è¯åŠ©æ‰‹
                            tool_outputs.append({
                                "tool_call_id": tool_call.id,
                                "output": json.dumps({
                                    "status": "success" if book_data else "not_found",
                                    "book": book_data
                                })
                            })

                    # æäº¤å‡½æ•°æ‰§è¡Œç»“æœç»™ OpenAI
                    client.beta.threads.runs.submit_tool_outputs(
                        thread_id=thread_id,
                        run_id=run.id,
                        tool_outputs=tool_outputs
                    )
            elif run_status.status in ['failed', 'cancelled', 'expired']:
                return jsonify({"error": f"Assistant run failed: {run_status.status}"}), 500

            # çŸ­æš‚ç­‰å¾…åå†æ£€æŸ¥çŠ¶æ€
            time.sleep(0.5)

        # è·å–æœ€æ–°çš„åŠ©æ‰‹å›å¤
        messages = client.beta.threads.messages.list(thread_id=thread_id)

        # è·å–æœ€æ–°çš„åŠ©æ‰‹å›å¤ï¼ˆç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯æœ€æ–°çš„ï¼‰
        assistant_message = None
        for msg in messages.data:
            if msg.role == "assistant":
                assistant_message = msg
                break

        if not assistant_message:
            return jsonify({"error": "No response received from assistant"}), 500

        # æå–æ–‡æœ¬å†…å®¹
        ai_response = ""
        for content in assistant_message.content:
            if content.type == "text":
                if content.text.annotations:
                    print(content.text.annotations)
                print('-------')
                print(assistant_message)
                # ä½¿ç”¨ openai_assistant æ¨¡å—ä¸­çš„ clean_text å‡½æ•°æ¸…ç†æ–‡æœ¬
                ai_response += openai_assistant.clean_text(content.text.value)

        # ç”Ÿæˆè¯­éŸ³
        audio_data = openai_service.text_to_speech(ai_response)

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜éŸ³é¢‘
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as temp_file:
            temp_file.write(audio_data)
            audio_path = temp_file.name

        # æ„å»ºå“åº”
        response = {
            "text": ai_response,
            "audio_url": f"/api/audio/{os.path.basename(audio_path)}",
            "function_results": function_results  # æ·»åŠ å‡½æ•°è°ƒç”¨ç»“æœ
        }

        # ä¿å­˜æ–‡ä»¶è·¯å¾„ä»¥ä¾¿åç»­è¯·æ±‚
        current_app.config[f"TEMP_AUDIO_{os.path.basename(audio_path)}"] = audio_path

        return jsonify(response)

    except Exception as e:
        return jsonify({"error": str(e)}), 500
