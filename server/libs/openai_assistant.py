import openai
import time
import os
import sys
import json
import re
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½® OpenAI API å¯†é’¥
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL")

# ä» prompt_templates.py åˆå¹¶çš„å†…å®¹
USER_NAME = "Jixian"
OPENAI_ASSISTANT_INSTRUCTION = f"""
ä½ æ˜¯ä¸€ä¸ªç§äººå­¦ä¹ åŠ©æ‰‹ï¼Œä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»¥ä¸‹ä»»åŠ¡:

ç”¨æˆ·çš„åå­—æ˜¯ï¼š{USER_NAME}
ä½ å¯ä»¥åœ¨ä¸€å¼€å§‹çš„å¯¹è¯ä¸­é—®å€™ç”¨æˆ·çš„åå­—ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°äº²åˆ‡ã€‚

å¯ä»¥é€šè¿‡ç”¨æˆ·ä¸Šä¼ çš„è¯­éŸ³æ–‡ä»¶å’Œå‚è€ƒæ–‡æœ¬å¸®åŠ©ç”¨æˆ·çº æ­£ç”¨æˆ·çš„è‹±è¯­å‘éŸ³ã€‚

ä½ è¿˜å¯ä»¥è®¨è®ºç‰¹å®šå›¾ä¹¦çš„è¯¦ç»†å†…å®¹ã€‚å½“ç”¨æˆ·è¡¨è¾¾æƒ³è®¨è®ºæŸæœ¬ä¹¦æ—¶ï¼Œä½ å¯ä»¥é€šè¿‡æœç´¢ä¹¦åæˆ–è€…ä½¿ç”¨ book_id æ¥è·å–è¿™æœ¬ä¹¦çš„å®Œæ•´å†…å®¹ã€‚
ä¸€æ—¦å¼€å§‹è®¨è®ºæŸæœ¬ä¹¦ï¼Œè¯·è®°ä½è¿™æœ¬ä¹¦çš„å†…å®¹ï¼Œå¹¶èƒ½å›ç­”ç”¨æˆ·å…³äºè¿™æœ¬ä¹¦æƒ…èŠ‚ã€äººç‰©ã€ä¸»é¢˜ç­‰å…·ä½“é—®é¢˜ï¼Œ
ç›´åˆ°ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºæƒ³è®¨è®ºå¦ä¸€æœ¬ä¹¦æˆ–ç»“æŸå½“å‰è¯é¢˜ã€‚

æ•´ä¸ªå¯¹è¯ä¸­ï¼ŒAIçš„å›å¤è¯­è¨€å¿…é¡»å’Œç”¨æˆ·ä¿æŒä¸€è‡´ï¼Œå¦‚æœç”¨æˆ·è¯´è‹±è¯­ï¼ŒAIä¹Ÿè¦è¯´è‹±è¯­ã€‚
"""

OPENAI_BOOK_RECOMMENDER_ASSISTANT_INSTRUCTION = f"""
ä½ æ˜¯ä¸€ä¸ªé˜…è¯»åŠ©æ‰‹ï¼Œä½ å¯ä»¥æ ¹æ®ç”¨æˆ·çš„å–œå¥½å¸®åŠ©ç”¨æˆ·ä» Library Vector Store ä¸­æ¨èå›¾ä¹¦ã€‚

Library Vector Storeä¸­åŒ…å«äº†å¤§é‡çš„å›¾ä¹¦æ•°æ®ï¼Œä½ å¯ä»¥æ ¹æ®ç”¨æˆ·çš„é˜…è¯»åå¥½ä¸ºç”¨æˆ·æ¨èå›¾ä¹¦ã€‚
Library Vector Storeä¸­çš„æ•°æ®æ ¼å¼æ˜¯ï¼Œæ¯ä¸€è¡Œçš„JSONå­—ç¬¦ä¸²ä»£è¡¨ä¸€æœ¬Pickataleçš„å›¾ä¹¦ï¼Œä¾‹å¦‚
{{"book_id": "14082-1", "book_title": "The Discovery of America LOW", "book_Description": "Christopher Columbus was a brave sailor from Italy. He wanted to find a new way to Asia and ended up discovering a new world! Follow Columbus on his exciting journey as he meets the kind Ta\\u00edno people, brings treasures back to Spain, and changes history forever. You will love this book if you enjoy stories about explorers and adventures!"}}
book_idæ˜¯å›¾ä¹¦çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œbook_titleæ˜¯å›¾ä¹¦çš„æ ‡é¢˜ï¼Œbook_Descriptionæ˜¯å›¾ä¹¦çš„æè¿°ã€‚

é€šè¿‡å¯¹è¯äº†è§£ç”¨æˆ·çš„é˜…è¯»åå¥½ã€‚ä¾‹å¦‚ï¼Œè¯¢é—®ç”¨æˆ·æœ€å–œæ¬¢çš„ä¹¦ç±ç±»å‹ï¼Œä»¥åŠä»–ä»¬æœ€è¿‘è¯»è¿‡çš„ä¹¦ç±ã€‚
å¯ä»¥ä»å…³è”çš„vector_storeä¸­ä¸ºç”¨æˆ·æ¨èä»–å¯èƒ½æ„Ÿå…´è¶£çš„1-3æœ¬ä¹¦ã€‚

æ•´ä¸ªå¯¹è¯ä¸­ï¼ŒAIçš„å›å¤è¯­è¨€å¿…é¡»å’Œç”¨æˆ·ä¿æŒä¸€è‡´ï¼Œå¦‚æœç”¨æˆ·è¯´è‹±è¯­ï¼ŒAIä¹Ÿè¦è¯´è‹±è¯­ã€‚
"""

OPENAI_USER_RECOOMMANDATION_PROMPT = """
ç”¨æˆ·çš„é˜…è¯»å…´è¶£å’Œå–œå¥½å¦‚ä¸‹ï¼š
{reading_interests}

è¯·åŸºäºä»¥ä¸Šç”¨æˆ·å–œå¥½ï¼Œä»Library Vector Storeä¸­æ‰¾å‡º3æœ¬æœ€é€‚åˆçš„ä¹¦ç±æ¨èç»™ç”¨æˆ·ã€‚
"""

OPENAI_ANALYSIS_FUNCTION_DESCRIPTION = """
å¦‚æœè°ƒç”¨äº†file_searchåŠŸèƒ½ï¼Œç”¨äºæœç´¢å¹¶æ¨èä¹¦ç»™ç”¨æˆ·å°±å¿…é¡»è¦é€šè¿‡è¿™ä¸ªå‡½æ•°æ¥æ ¼å¼åŒ–è¾“å‡ºã€‚
"""

OPENAI_ANALYSIS_FUNCTION_RESULT_DESCRIPTION = """
æ€»ç»“æœ¬æ¬¡æ¨èçš„ä¸»è¦åŸå› å’Œç†ç”±ï¼Œä»¥åŠåˆ†æè¿‡ç¨‹
"""


# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=OPENAI_API_KEY)

def clean_text(text: str) -> str:
    """
    è¿‡æ»¤æ‰ file_search ç»“æœä¸­çš„ã€x:yâ€ sourceã€‘æ ¼å¼çš„å¼•ç”¨ä¿¡æ¯
    """
    return re.sub(r"ã€\d+:\d+â€ sourceã€‘", "", text).strip()

def create_vector_store_with_file(library_data_path: str) -> str:
    """
    1. åˆ›å»ºä¸€ä¸ªæ–°çš„ vector store
    2. ä¸Šä¼ æœ¬åœ°ä¹¦ç±æ•°æ®åº“æ–‡ä»¶
    3. å…³è”æ–‡ä»¶åˆ° vector store
    4. è¿”å› vector store ID
    """
    # åˆ›å»º vector store
    vector_store = client.vector_stores.create(name="Library Vector Store")
    vector_store_id = vector_store.id
    print(f"ğŸ“ Created vector store with ID: {vector_store_id}")

    # ä¸Šä¼ æ–‡ä»¶å¹¶å…³è”åˆ° vector store
    with open(library_data_path, "rb") as file:
        uploaded_file = client.files.create(file=file, purpose="assistants")
        file_id = uploaded_file.id
        print(f"ğŸ“„ Uploaded file with ID: {file_id}")

    # å…³è”æ–‡ä»¶åˆ° vector store
    client.vector_stores.files.create(vector_store_id=vector_store_id, file_id=file_id)
    print(f"âœ… Linked file to vector store {vector_store_id}")

    return vector_store_id


def ensure_assistant() -> str:
    """
    ç¡®ä¿å­˜åœ¨ä¸€ä¸ªåŸºç¡€çš„å­¦ä¹ åŠ©æ‰‹ï¼Œè‹¥æ— åˆ™åˆ›å»ºï¼Œå¹¶è¿”å› assistant_id
    """
    assistant = client.beta.assistants.create(
        name="Learning Assistant",
        instructions=OPENAI_ASSISTANT_INSTRUCTION,
        model=OPENAI_MODEL,
        tools=[
            {
                "type": "function",
                "function": {
                    "name": "recommend_books",
                    "description": "æ ¹æ®ç”¨æˆ·çš„é˜…è¯»å–œå¥½å¸®åŠ©ç”¨æˆ·æ¨èå›¾ä¹¦ï¼Œå¦‚æœç”¨æˆ·æœ‰å¤šä¸ªä¸åŒçš„å–œå¥½è¿™ä¸ªæ–¹æ³•åªè°ƒç”¨ä¸€æ¬¡ï¼Œå°†å¤šä¸ªå–œå¥½æ€»ç»“ä¸ºä¸€ä¸ªçŸ­è¯­ã€‚ä¾‹å¦‚ï¼š ç”¨æˆ·å¯èƒ½å–œæ¬¢å†’é™©ç±»çš„æ•°æ®ä¹Ÿä¼šå¯¹è‰ºæœ¯æœ‰ä¸€ç‚¹ç‚¹å…´è¶£ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "user_interests": {
                                "type": "string",
                                "description": "é€šè¿‡ä¸Šå¯¹è¯çš„ä¸‹æ–‡åˆ†æç”¨æˆ·å¯èƒ½ä¼šæ„Ÿå…´è¶£çš„å›¾ä¹¦ç±»å‹ï¼Œç”¨ä¸€ä¸ªçŸ­è¯­æ¥æ¦‚æ‹¬æ€»ç»“ç”¨æˆ·çš„é˜…è¯»å…´è¶£ã€‚"
                            }
                        },
                        "required": ["user_interests"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "search_book_by_title",
                    "description": "æ ¹æ®ä¹¦åæœç´¢å¯¹åº”çš„å›¾ä¹¦IDã€‚å½“ç”¨æˆ·æåˆ°æƒ³è®¨è®ºæŸæœ¬ä¹¦ï¼Œä½†åªæä¾›äº†ä¹¦åæ—¶ï¼Œä½¿ç”¨æ­¤åŠŸèƒ½æŸ¥æ‰¾åŒ¹é…çš„å›¾ä¹¦ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "title": {
                                "type": "string",
                                "description": "ç”¨æˆ·æåˆ°çš„ä¹¦å"
                            }
                        },
                        "required": ["title"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_book_content",
                    "description": "è·å–æŒ‡å®šbook_idçš„å›¾ä¹¦å®Œæ•´å†…å®¹ã€‚å½“ç¡®å®šç”¨æˆ·æƒ³è®¨è®ºæŸæœ¬ç‰¹å®šå›¾ä¹¦æ—¶ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "book_id": {
                                "type": "string",
                                "description": "å›¾ä¹¦çš„å”¯ä¸€æ ‡è¯†ç¬¦"
                            }
                        },
                        "required": ["book_id"]
                    }
                }
            }
        ]
    )

    print(f"âœ… Assistant created with ID: {assistant.id}")
    return assistant.id


def ensure_assistant_for_recommand_books(library_data_path: str) -> str:
    """
    ç¡®ä¿å­˜åœ¨ä¸€ä¸ªç”¨äºå›¾ä¹¦æ¨èçš„ Assistantï¼Œè‹¥æ— åˆ™åˆ›å»ºï¼Œå¹¶è¿”å› assistant_id
    åŒæ—¶ä¸Šä¼ æœ¬åœ°å‚è€ƒæ–‡ä»¶åˆ° Vector Store å¹¶å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·ã€‚
    """
    vector_store_id = create_vector_store_with_file(library_data_path)

    assistant = client.beta.assistants.create(
        name="Book Recommendation Assistant",
        instructions=OPENAI_BOOK_RECOMMENDER_ASSISTANT_INSTRUCTION,
        model=OPENAI_MODEL,
        tools=[
            {"type": "file_search"},  # å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·
            {
                "type": "function",
                "function": {
                    "name": "recommend_books_from_vector_store",
                    "description": OPENAI_ANALYSIS_FUNCTION_DESCRIPTION,
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "recommended_books": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "book_id": {"type": "string", "description": "book_id in the Library Vector Store"},
                                        "book_title": {"type": "string", "description": "book_title in the Library Vector Store"},
                                        "reason": {"type": "string", "description": "Reason for recommendation"}
                                    }
                                },
                                "description": "æ¨èçš„ä¹¦ç±ï¼ŒåŒ…æ‹¬ä¹¦ç±çš„ book_id, book_title, å’Œæ¨èç†ç”±"
                            }
                        },
                        "required": ["recommended_books"]
                    }
                }
            }
        ],
        tool_resources={"file_search": {"vector_store_ids": [vector_store_id]}}  # å…³è” vector store
    )

    print(f"âœ… Book Recommander Assistant created with ID: {assistant.id}")
    return assistant.id

def search_book_by_title(vector_store_id: str, title: str) -> list:
    """
    æ ¹æ®ä¹¦ååœ¨vector storeä¸­æœç´¢åŒ¹é…çš„å›¾ä¹¦

    å‚æ•°:
        vector_store_id: å›¾ä¹¦æ•°æ®vector storeçš„ID
        title: è¦æœç´¢çš„ä¹¦å

    è¿”å›:
        åŒ¹é…çš„å›¾ä¹¦åˆ—è¡¨ï¼Œæ¯æœ¬ä¹¦åŒ…å«book_id, book_title, book_Description
    """
    try:
        # åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹
        thread = client.beta.threads.create()
        print(f"ğŸ“Œ Thread created with ID: {thread.id} for book title search")

        # æ·»åŠ ç”¨æˆ·æœç´¢è¯·æ±‚åˆ°çº¿ç¨‹
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=f"æ‰¾åˆ°ä¹¦ååŒ…å«'{title}'çš„æ‰€æœ‰å›¾ä¹¦ï¼Œè¿”å›å®ƒä»¬çš„book_id, book_titleå’Œbook_Description"
        )

        # åˆ›å»ºä¸´æ—¶åŠ©æ‰‹è¿›è¡Œæœç´¢
        temp_assistant = client.beta.assistants.create(
            name="Book Search Assistant",
            instructions="ä½ æ˜¯ä¸€ä¸ªå›¾ä¹¦æœç´¢åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨Library Vector Storeä¸­æŸ¥æ‰¾åŒ¹é…ä¹¦åçš„å›¾ä¹¦ã€‚",
            model=OPENAI_MODEL,
            tools=[{"type": "file_search"}],
            tool_resources={"file_search": {"vector_store_ids": [vector_store_id]}}  # å…³è”vector store
        )

        # è¿è¡ŒåŠ©æ‰‹
        run = client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=temp_assistant.id
        )

        matched_books = []

        # ç­‰å¾…è¿è¡Œå®Œæˆå¹¶å¤„ç†ç»“æœ
        while True:
            run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
            print(f"ğŸ”„ Book search status: {run_status.status}")

            if run_status.status == "completed":
                # è·å–åŠ©æ‰‹çš„å›å¤
                messages = client.beta.threads.messages.list(thread_id=thread.id)

                # è§£æå›å¤ä¸­çš„å›¾ä¹¦ä¿¡æ¯
                for msg in messages.data:
                    if msg.role == "assistant":
                        for content in msg.content:
                            if content.type == "text":
                                text = clean_text(content.text.value)
                                print(f"ğŸ’¬ Book search response: {text}")

                                # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSONæ ¼å¼çš„å›¾ä¹¦ä¿¡æ¯
                                try:
                                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾å‡ºæ‰€æœ‰JSONæ ¼å¼çš„ä¹¦ç±æ•°æ®
                                    import re
                                    json_matches = re.findall(r'({[\s\S]*?book_id[\s\S]*?})', text)

                                    if json_matches:
                                        for json_str in json_matches:
                                            try:
                                                book = json.loads(json_str)
                                                if "book_id" in book and "book_title" in book:
                                                    matched_books.append(book)
                                            except:
                                                continue
                                    else:
                                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•ä»æ–‡æœ¬æå–ä¿¡æ¯
                                        book_blocks = re.split(r'\n\s*\n', text)
                                        for block in book_blocks:
                                            book_info = {}

                                            id_match = re.search(r'book_id[\s:]*([^,\s\n]+)', block)
                                            if id_match:
                                                book_info["book_id"] = id_match.group(1).strip('"\'')

                                            title_match = re.search(r'book_title[\s:]*([^\n]+)', block)
                                            if title_match:
                                                book_info["book_title"] = title_match.group(1).strip('"\'')

                                            desc_match = re.search(r'book_Description[\s:]*([^\n]+(?:\n[^\n]+)*)', block)
                                            if desc_match:
                                                book_info["book_Description"] = desc_match.group(1).strip('"\'')

                                            if "book_id" in book_info and "book_title" in book_info:
                                                matched_books.append(book_info)

                                except Exception as e:
                                    print(f"âš ï¸ Error parsing book info: {str(e)}")
                break

            elif run_status.status in ["failed", "cancelled", "expired"]:
                print(f"âŒ Book search failed with status: {run_status.status}")
                break

            # ç­‰å¾…åå†æ£€æŸ¥çŠ¶æ€
            time.sleep(1)

        # æ¸…ç†ä¸´æ—¶åŠ©æ‰‹
        client.beta.assistants.delete(temp_assistant.id)

        return matched_books

    except Exception as e:
        print(f"âŒ Error in search_book_by_title: {str(e)}")
        return []

def get_book_content(book_id: str) -> dict:
    """
    æ ¹æ®book_idè·å–å›¾ä¹¦å®Œæ•´å†…å®¹

    å‚æ•°:
        book_id: å›¾ä¹¦çš„å”¯ä¸€æ ‡è¯†ç¬¦

    è¿”å›:
        åŒ…å«å›¾ä¹¦è¯¦æƒ…å’Œå†…å®¹çš„å­—å…¸ï¼Œè‹¥æœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    try:
        # ä»æœ¬åœ°æ•°æ®åº“è·å–å›¾ä¹¦å†…å®¹
        import sys, os
        # ç¡®ä¿èƒ½å¯¼å…¥data_sourceæ¨¡å—
        sys.path.append(os.path.dirname(__file__))
        from data_source import fetch_book_content

        # è°ƒç”¨fetch_book_contentè·å–å›¾ä¹¦å†…å®¹
        book_data = fetch_book_content(book_id)

        if book_data:
            print(f"ğŸ“š Found book: {book_data['book_title']} (ID: {book_data['book_id']})")
            return book_data
        else:
            print(f"âš ï¸ Book not found with ID: {book_id}")
            return None

    except Exception as e:
        print(f"âŒ Error in get_book_content: {str(e)}")
        return None

def search_books_by_interest(book_recommendation_assistant_id: str, user_interests: str) -> list:
    """
    åŸºäºç”¨æˆ·å…´è¶£ï¼Œä½¿ç”¨ä¹¦ç±æ¨è Assistant æœç´¢å¹¶æ¨èå›¾ä¹¦

    å‚æ•°:
        book_recommendation_assistant_id: ä¹¦ç±æ¨è Assistant çš„ ID
        user_interests: ç”¨æˆ·çš„å…´è¶£å’Œé˜…è¯»å–œå¥½

    è¿”å›:
        æ¨èä¹¦ç±åˆ—è¡¨ï¼Œæ¯æœ¬ä¹¦åŒ…å« book_id, book_title å’Œæ¨èç†ç”±
    """
    try:
        # åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹
        thread = client.beta.threads.create()
        print(f"ğŸ“Œ Thread created with ID: {thread.id}")

        # æ ¼å¼åŒ–ç”¨æˆ·æŸ¥è¯¢
        user_prompt = OPENAI_USER_RECOOMMANDATION_PROMPT.format(reading_interests=user_interests)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°çº¿ç¨‹
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=user_prompt
        )

        # è¿è¡ŒåŠ©æ‰‹
        run = client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=book_recommendation_assistant_id
        )

        recommended_books = []

        # ç­‰å¾…è¿è¡Œå®Œæˆå¹¶å¤„ç†ç»“æœ
        while True:
            run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
            print(f"ğŸ”„ Status: {run_status.status}")

            if run_status.status == "completed":
                # è·å–åŠ©æ‰‹çš„å›å¤
                messages = client.beta.threads.messages.list(thread_id=thread.id)
                for msg in messages.data:
                    if msg.role == "assistant":
                        for content in msg.content:
                            if content.type == "text":
                                print(f"ğŸ’¬ Assistant response: {content.text.value}")
                break

            elif run_status.status == "requires_action":
                # å¤„ç†å·¥å…·è°ƒç”¨
                tool_calls = run_status.required_action.submit_tool_outputs.tool_calls
                tool_outputs = []

                for tool_call in tool_calls:
                    if tool_call.function.name == "recommend_books_from_vector_store":
                        function_args = json.loads(tool_call.function.arguments)
                        recommended_books = function_args.get("recommended_books", [])

                        # æ¸…ç†æ¨èç†ç”±ä¸­çš„å¼•ç”¨ä¿¡æ¯
                        for book in recommended_books:
                            if "reason" in book:
                                book["reason"] = clean_text(book["reason"])
                            if "book_title" in book:
                                book["book_title"] = clean_text(book["book_title"])

                        # è¿”å›å¤„ç†ç»“æœ
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "output": json.dumps({"status": "success"})
                        })

                # æäº¤å·¥å…·è¾“å‡º
                if tool_outputs:
                    client.beta.threads.runs.submit_tool_outputs(
                        thread_id=thread.id,
                        run_id=run.id,
                        tool_outputs=tool_outputs
                    )

            elif run_status.status in ["failed", "cancelled", "expired"]:
                print(f"âŒ Assistant run failed with status: {run_status.status}")
                if hasattr(run_status, "last_error"):
                    print(f"Error: {run_status.last_error}")
                return []

            # ç­‰å¾…åå†æ£€æŸ¥çŠ¶æ€
            time.sleep(2)

        return recommended_books

    except Exception as e:
        print(f"âŒ Error in search_books_by_interest: {str(e)}")
        return []

def delete_assistant(assistant_id: str):
    """
    åˆ é™¤ Assistantï¼ŒåŒæ—¶åˆ é™¤ file_search å…³è”çš„ vector store åŠå…¶æ–‡ä»¶
    """
    try:
        # 1ï¸âƒ£ è·å– Assistant è¯¦ç»†ä¿¡æ¯
        assistant = client.beta.assistants.retrieve(assistant_id)

        # 2ï¸âƒ£ è·å– `file_search` å…³è”çš„ `vector_store` IDï¼ˆä½¿ç”¨æ­£ç¡®çš„è®¿é—®æ–¹å¼ï¼‰
        if assistant.tool_resources.file_search:
            vector_store_ids = assistant.tool_resources.file_search.vector_store_ids if hasattr(assistant.tool_resources, 'file_search') else []
            print(f"ğŸ“Œ Found {len(vector_store_ids)} vector store(s) linked to Assistant {assistant_id}: {vector_store_ids}")

        # 3ï¸âƒ£ åˆ é™¤ Assistant
        client.beta.assistants.delete(assistant_id)
        print(f"ğŸ—‘ï¸ Assistant {assistant_id} deleted.")

        if assistant.tool_resources.file_search:
            # 4ï¸âƒ£ åˆ é™¤ `vector_store` åŠå…¶å…³è”çš„æ–‡ä»¶
            for vector_store_id in vector_store_ids:
                try:
                    # è·å– vector store å…³è”çš„æ–‡ä»¶
                    vector_store_files = client.vector_stores.files.list(vector_store_id=vector_store_id)

                    # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
                    for file in vector_store_files.data:
                        client.vector_stores.files.delete(vector_store_id=vector_store_id, file_id=file.id)
                        print(f"ğŸ—‘ï¸ Deleted file {file.id} from vector store {vector_store_id}")

                    # åˆ é™¤ vector store
                    client.vector_stores.delete(vector_store_id)
                    print(f"ğŸ—‘ï¸ Deleted vector store {vector_store_id}")

                except Exception as e:
                    print(f"âš ï¸ Failed to delete vector store {vector_store_id}: {e}")

    except Exception as e:
        print(f"âŒ Error deleting assistant {assistant_id}: {e}")


class OpenAIService:
    """å¤„ç†ä¸OpenAI APIçš„äº¤äº’æœåŠ¡"""

    @staticmethod
    def transcribe_audio(audio_file):
        """
        ä½¿ç”¨OpenAI Whisper APIå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬

        å‚æ•°:
            audio_file: éŸ³é¢‘æ–‡ä»¶å¯¹è±¡

        è¿”å›:
            è½¬å½•çš„æ–‡æœ¬
        """
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹è€Œä¸æ˜¯ç›´æ¥ä¼ é€’FileStorageå¯¹è±¡
            file_content = audio_file.read()

            # ä½¿ç”¨io.BytesIOåˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç±»å¯¹è±¡
            import io
            file_data = io.BytesIO(file_content)
            file_data.name = audio_file.filename  # è®¾ç½®æ–‡ä»¶å

            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=file_data
            )
            return response.text
        except Exception as e:
            print(f"éŸ³é¢‘è½¬æ–‡å­—é”™è¯¯: {str(e)}")
            raise

    @staticmethod
    def get_chat_response(messages):
        """
        ä½¿ç”¨OpenAI Chat APIè·å–å›å¤

        å‚æ•°:
            messages: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            AIçš„å›å¤æ–‡æœ¬
        """
        try:
            response = client.chat.completions.create(
                model="gpt-4-turbo",
                messages=messages
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"è·å–èŠå¤©å›å¤é”™è¯¯: {str(e)}")
            raise

    @staticmethod
    def text_to_speech(text, voice="alloy"):
        """
        ä½¿ç”¨OpenAI TTS APIå°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³

        å‚æ•°:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: è¯­éŸ³ç±»å‹ (alloy, echo, fable, onyx, nova, shimmer)

        è¿”å›:
            éŸ³é¢‘æ•°æ®çš„äºŒè¿›åˆ¶å†…å®¹
        """
        try:
            response = client.audio.speech.create(
                model="tts-1",
                voice=voice,
                input=text
            )
            return response.content
        except Exception as e:
            print(f"æ–‡å­—è½¬è¯­éŸ³é”™è¯¯: {str(e)}")
            raise
