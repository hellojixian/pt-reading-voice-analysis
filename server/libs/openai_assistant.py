import openai
import time
import os
import sys
import json
import re
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½® OpenAI API å¯†é’¥
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL")

# ä» prompt_templates.py åˆå¹¶çš„å†…å®¹
USER_NAME = "Jixian"
OPENAI_ASSISTANT_INSTRUCTION = f"""
ä½ æ˜¯ä¸€ä¸ªç§äººå­¦ä¹ åŠ©æ‰‹ï¼Œä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»¥ä¸‹ä»»åŠ¡:

ç”¨æˆ·çš„åå­—æ˜¯ï¼š{USER_NAME}
ä½ å¯ä»¥åœ¨ä¸€å¼€å§‹çš„å¯¹è¯ä¸­é—®å€™ç”¨æˆ·çš„åå­—ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°äº²åˆ‡ã€‚

å¯ä»¥é€šè¿‡ç”¨æˆ·ä¸Šä¼ çš„è¯­éŸ³æ–‡ä»¶å’Œå‚è€ƒæ–‡æœ¬å¸®åŠ©ç”¨æˆ·çº æ­£ç”¨æˆ·çš„è‹±è¯­å‘éŸ³ã€‚

æ•´ä¸ªå¯¹è¯ä¸­ï¼ŒAIçš„å›å¤è¯­è¨€å¿…é¡»å’Œç”¨æˆ·ä¿æŒä¸€è‡´ï¼Œå¦‚æœç”¨æˆ·è¯´è‹±è¯­ï¼ŒAIä¹Ÿè¦è¯´è‹±è¯­ã€‚
"""

OPENAI_BOOK_RECOMMENDER_ASSISTANT_INSTRUCTION = f"""
ä½ æ˜¯ä¸€ä¸ªé˜…è¯»åŠ©æ‰‹ï¼Œä½ å¯ä»¥æ ¹æ®ç”¨æˆ·çš„å–œå¥½å¸®åŠ©ç”¨æˆ·ä» Library Vector Store ä¸­æ¨èå›¾ä¹¦ã€‚

Library Vector Storeä¸­åŒ…å«äº†å¤§é‡çš„å›¾ä¹¦æ•°æ®ï¼Œä½ å¯ä»¥æ ¹æ®ç”¨æˆ·çš„é˜…è¯»åå¥½ä¸ºç”¨æˆ·æ¨èå›¾ä¹¦ã€‚
Library Vector Storeä¸­çš„æ•°æ®æ ¼å¼æ˜¯ï¼Œæ¯ä¸€è¡Œçš„JSONå­—ç¬¦ä¸²ä»£è¡¨ä¸€æœ¬Pickataleçš„å›¾ä¹¦ï¼Œä¾‹å¦‚
{{"book_id": "14082-1", "book_title": "The Discovery of America LOW", "book_Description": "Christopher Columbus was a brave sailor from Italy. He wanted to find a new way to Asia and ended up discovering a new world! Follow Columbus on his exciting journey as he meets the kind Ta\\u00edno people, brings treasures back to Spain, and changes history forever. You will love this book if you enjoy stories about explorers and adventures!"}}
book_idæ˜¯å›¾ä¹¦çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œbook_titleæ˜¯å›¾ä¹¦çš„æ ‡é¢˜ï¼Œbook_Descriptionæ˜¯å›¾ä¹¦çš„æè¿°ã€‚

é€šè¿‡å¯¹è¯äº†è§£ç”¨æˆ·çš„é˜…è¯»åå¥½ã€‚ä¾‹å¦‚ï¼Œè¯¢é—®ç”¨æˆ·æœ€å–œæ¬¢çš„ä¹¦ç±ç±»å‹ï¼Œä»¥åŠä»–ä»¬æœ€è¿‘è¯»è¿‡çš„ä¹¦ç±ã€‚
å¯ä»¥ä»å…³è”çš„vector_storeä¸­ä¸ºç”¨æˆ·æ¨èä»–å¯èƒ½æ„Ÿå…´è¶£çš„1-3æœ¬ä¹¦ã€‚

æ•´ä¸ªå¯¹è¯ä¸­ï¼ŒAIçš„å›å¤è¯­è¨€å¿…é¡»å’Œç”¨æˆ·ä¿æŒä¸€è‡´ï¼Œå¦‚æœç”¨æˆ·è¯´è‹±è¯­ï¼ŒAIä¹Ÿè¦è¯´è‹±è¯­ã€‚
"""

OPENAI_USER_RECOOMMANDATION_PROMPT = """
ç”¨æˆ·çš„é˜…è¯»å…´è¶£å’Œå–œå¥½å¦‚ä¸‹ï¼š
{reading_interests}

è¯·åŸºäºä»¥ä¸Šç”¨æˆ·å–œå¥½ï¼Œä»Library Vector Storeä¸­æ‰¾å‡º3æœ¬æœ€é€‚åˆçš„ä¹¦ç±æ¨èç»™ç”¨æˆ·ã€‚
"""

OPENAI_ANALYSIS_FUNCTION_DESCRIPTION = """
å¦‚æœè°ƒç”¨äº†file_searchåŠŸèƒ½ï¼Œç”¨äºæœç´¢å¹¶æ¨èä¹¦ç»™ç”¨æˆ·å°±å¿…é¡»è¦é€šè¿‡è¿™ä¸ªå‡½æ•°æ¥æ ¼å¼åŒ–è¾“å‡ºã€‚
"""

OPENAI_ANALYSIS_FUNCTION_RESULT_DESCRIPTION = """
æ€»ç»“æœ¬æ¬¡æ¨èçš„ä¸»è¦åŸå› å’Œç†ç”±ï¼Œä»¥åŠåˆ†æè¿‡ç¨‹
"""


# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=OPENAI_API_KEY)

def clean_text(text: str) -> str:
    """
    è¿‡æ»¤æ‰ file_search ç»“æœä¸­çš„ã€x:yâ€ sourceã€‘æ ¼å¼çš„å¼•ç”¨ä¿¡æ¯
    """
    return re.sub(r"ã€\d+:\d+â€ sourceã€‘", "", text).strip()

def create_vector_store_with_file(library_data_path: str) -> str:
    """
    1. åˆ›å»ºä¸€ä¸ªæ–°çš„ vector store
    2. ä¸Šä¼ æœ¬åœ°ä¹¦ç±æ•°æ®åº“æ–‡ä»¶
    3. å…³è”æ–‡ä»¶åˆ° vector store
    4. è¿”å› vector store ID
    """
    # åˆ›å»º vector store
    vector_store = client.vector_stores.create(name="Library Vector Store")
    vector_store_id = vector_store.id
    print(f"ğŸ“ Created vector store with ID: {vector_store_id}")

    # ä¸Šä¼ æ–‡ä»¶å¹¶å…³è”åˆ° vector store
    with open(library_data_path, "rb") as file:
        uploaded_file = client.files.create(file=file, purpose="assistants")
        file_id = uploaded_file.id
        print(f"ğŸ“„ Uploaded file with ID: {file_id}")

    # å…³è”æ–‡ä»¶åˆ° vector store
    client.vector_stores.files.create(vector_store_id=vector_store_id, file_id=file_id)
    print(f"âœ… Linked file to vector store {vector_store_id}")

    return vector_store_id


def ensure_assistant() -> str:
    """
    ç¡®ä¿å­˜åœ¨ä¸€ä¸ªåŸºç¡€çš„å­¦ä¹ åŠ©æ‰‹ï¼Œè‹¥æ— åˆ™åˆ›å»ºï¼Œå¹¶è¿”å› assistant_id
    """
    assistant = client.beta.assistants.create(
        name="Learning Assistant",
        instructions=OPENAI_ASSISTANT_INSTRUCTION,
        model=OPENAI_MODEL,
        tools=[
            {
                "type": "function",
                "function": {
                    "name": "recommend_books",
                    "description": "æ ¹æ®ç”¨æˆ·çš„é˜…è¯»å–œå¥½å¸®åŠ©ç”¨æˆ·æ¨èå›¾ä¹¦ï¼Œå¦‚æœç”¨æˆ·æœ‰å¤šä¸ªä¸åŒçš„å–œå¥½è¿™ä¸ªæ–¹æ³•åªè°ƒç”¨ä¸€æ¬¡ï¼Œå°†å¤šä¸ªå–œå¥½æ€»ç»“ä¸ºä¸€ä¸ªçŸ­è¯­ã€‚ä¾‹å¦‚ï¼š ç”¨æˆ·å¯èƒ½å–œæ¬¢å†’é™©ç±»çš„æ•°æ®ä¹Ÿä¼šå¯¹è‰ºæœ¯æœ‰ä¸€ç‚¹ç‚¹å…´è¶£ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "user_interests": {
                                "type": "string",
                                "description": "é€šè¿‡ä¸Šå¯¹è¯çš„ä¸‹æ–‡åˆ†æç”¨æˆ·å¯èƒ½ä¼šæ„Ÿå…´è¶£çš„å›¾ä¹¦ç±»å‹ï¼Œç”¨ä¸€ä¸ªçŸ­è¯­æ¥æ¦‚æ‹¬æ€»ç»“ç”¨æˆ·çš„é˜…è¯»å…´è¶£ã€‚"
                            }
                        },
                        "required": ["user_interests"]
                    }
                }
            }
        ]
    )

    print(f"âœ… Assistant created with ID: {assistant.id}")
    return assistant.id


def ensure_assistant_for_recommand_books(library_data_path: str) -> str:
    """
    ç¡®ä¿å­˜åœ¨ä¸€ä¸ªç”¨äºå›¾ä¹¦æ¨èçš„ Assistantï¼Œè‹¥æ— åˆ™åˆ›å»ºï¼Œå¹¶è¿”å› assistant_id
    åŒæ—¶ä¸Šä¼ æœ¬åœ°å‚è€ƒæ–‡ä»¶åˆ° Vector Store å¹¶å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·ã€‚
    """
    vector_store_id = create_vector_store_with_file(library_data_path)

    assistant = client.beta.assistants.create(
        name="Book Recommendation Assistant",
        instructions=OPENAI_BOOK_RECOMMENDER_ASSISTANT_INSTRUCTION,
        model=OPENAI_MODEL,
        tools=[
            {"type": "file_search"},  # å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·
            {
                "type": "function",
                "function": {
                    "name": "recommend_books_from_vector_store",
                    "description": OPENAI_ANALYSIS_FUNCTION_DESCRIPTION,
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "recommended_books": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "book_id": {"type": "string", "description": "book_id in the Library Vector Store"},
                                        "book_title": {"type": "string", "description": "book_title in the Library Vector Store"},
                                        "reason": {"type": "string", "description": "Reason for recommendation"}
                                    }
                                },
                                "description": "æ¨èçš„ä¹¦ç±ï¼ŒåŒ…æ‹¬ä¹¦ç±çš„ book_id, book_title, å’Œæ¨èç†ç”±"
                            }
                        },
                        "required": ["recommended_books"]
                    }
                }
            }
        ],
        tool_resources={"file_search": {"vector_store_ids": [vector_store_id]}}  # å…³è” vector store
    )

    print(f"âœ… Book Recommander Assistant created with ID: {assistant.id}")
    return assistant.id

def search_books_by_interest(book_recommendation_assistant_id: str, user_interests: str) -> list:
    """
    åŸºäºç”¨æˆ·å…´è¶£ï¼Œä½¿ç”¨ä¹¦ç±æ¨è Assistant æœç´¢å¹¶æ¨èå›¾ä¹¦

    å‚æ•°:
        book_recommendation_assistant_id: ä¹¦ç±æ¨è Assistant çš„ ID
        user_interests: ç”¨æˆ·çš„å…´è¶£å’Œé˜…è¯»å–œå¥½

    è¿”å›:
        æ¨èä¹¦ç±åˆ—è¡¨ï¼Œæ¯æœ¬ä¹¦åŒ…å« book_id, book_title å’Œæ¨èç†ç”±
    """
    try:
        # åˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹
        thread = client.beta.threads.create()
        print(f"ğŸ“Œ Thread created with ID: {thread.id}")

        # æ ¼å¼åŒ–ç”¨æˆ·æŸ¥è¯¢
        user_prompt = OPENAI_USER_RECOOMMANDATION_PROMPT.format(reading_interests=user_interests)

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°çº¿ç¨‹
        client.beta.threads.messages.create(
            thread_id=thread.id,
            role="user",
            content=user_prompt
        )

        # è¿è¡ŒåŠ©æ‰‹
        run = client.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=book_recommendation_assistant_id
        )

        recommended_books = []

        # ç­‰å¾…è¿è¡Œå®Œæˆå¹¶å¤„ç†ç»“æœ
        while True:
            run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
            print(f"ğŸ”„ Status: {run_status.status}")

            if run_status.status == "completed":
                # è·å–åŠ©æ‰‹çš„å›å¤
                messages = client.beta.threads.messages.list(thread_id=thread.id)
                for msg in messages.data:
                    if msg.role == "assistant":
                        for content in msg.content:
                            if content.type == "text":
                                print(f"ğŸ’¬ Assistant response: {content.text.value}")
                break

            elif run_status.status == "requires_action":
                # å¤„ç†å·¥å…·è°ƒç”¨
                tool_calls = run_status.required_action.submit_tool_outputs.tool_calls
                tool_outputs = []

                for tool_call in tool_calls:
                    if tool_call.function.name == "recommend_books_from_vector_store":
                        function_args = json.loads(tool_call.function.arguments)
                        recommended_books = function_args.get("recommended_books", [])

                        # æ¸…ç†æ¨èç†ç”±ä¸­çš„å¼•ç”¨ä¿¡æ¯
                        for book in recommended_books:
                            if "reason" in book:
                                book["reason"] = clean_text(book["reason"])
                            if "book_title" in book:
                                book["book_title"] = clean_text(book["book_title"])

                        # è¿”å›å¤„ç†ç»“æœ
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "output": json.dumps({"status": "success"})
                        })

                # æäº¤å·¥å…·è¾“å‡º
                if tool_outputs:
                    client.beta.threads.runs.submit_tool_outputs(
                        thread_id=thread.id,
                        run_id=run.id,
                        tool_outputs=tool_outputs
                    )

            elif run_status.status in ["failed", "cancelled", "expired"]:
                print(f"âŒ Assistant run failed with status: {run_status.status}")
                if hasattr(run_status, "last_error"):
                    print(f"Error: {run_status.last_error}")
                return []

            # ç­‰å¾…åå†æ£€æŸ¥çŠ¶æ€
            time.sleep(2)

        return recommended_books

    except Exception as e:
        print(f"âŒ Error in search_books_by_interest: {str(e)}")
        return []

def delete_assistant(assistant_id: str):
    """
    åˆ é™¤ Assistantï¼ŒåŒæ—¶åˆ é™¤ file_search å…³è”çš„ vector store åŠå…¶æ–‡ä»¶
    """
    try:
        # 1ï¸âƒ£ è·å– Assistant è¯¦ç»†ä¿¡æ¯
        assistant = client.beta.assistants.retrieve(assistant_id)

        # 2ï¸âƒ£ è·å– `file_search` å…³è”çš„ `vector_store` IDï¼ˆä½¿ç”¨æ­£ç¡®çš„è®¿é—®æ–¹å¼ï¼‰
        if assistant.tool_resources.file_search:
            vector_store_ids = assistant.tool_resources.file_search.vector_store_ids if hasattr(assistant.tool_resources, 'file_search') else []
            print(f"ğŸ“Œ Found {len(vector_store_ids)} vector store(s) linked to Assistant {assistant_id}: {vector_store_ids}")

        # 3ï¸âƒ£ åˆ é™¤ Assistant
        client.beta.assistants.delete(assistant_id)
        print(f"ğŸ—‘ï¸ Assistant {assistant_id} deleted.")

        if assistant.tool_resources.file_search:
            # 4ï¸âƒ£ åˆ é™¤ `vector_store` åŠå…¶å…³è”çš„æ–‡ä»¶
            for vector_store_id in vector_store_ids:
                try:
                    # è·å– vector store å…³è”çš„æ–‡ä»¶
                    vector_store_files = client.vector_stores.files.list(vector_store_id=vector_store_id)

                    # åˆ é™¤æ‰€æœ‰æ–‡ä»¶
                    for file in vector_store_files.data:
                        client.vector_stores.files.delete(vector_store_id=vector_store_id, file_id=file.id)
                        print(f"ğŸ—‘ï¸ Deleted file {file.id} from vector store {vector_store_id}")

                    # åˆ é™¤ vector store
                    client.vector_stores.delete(vector_store_id)
                    print(f"ğŸ—‘ï¸ Deleted vector store {vector_store_id}")

                except Exception as e:
                    print(f"âš ï¸ Failed to delete vector store {vector_store_id}: {e}")

    except Exception as e:
        print(f"âŒ Error deleting assistant {assistant_id}: {e}")


class OpenAIService:
    """å¤„ç†ä¸OpenAI APIçš„äº¤äº’æœåŠ¡"""

    @staticmethod
    def transcribe_audio(audio_file):
        """
        ä½¿ç”¨OpenAI Whisper APIå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬

        å‚æ•°:
            audio_file: éŸ³é¢‘æ–‡ä»¶å¯¹è±¡

        è¿”å›:
            è½¬å½•çš„æ–‡æœ¬
        """
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹è€Œä¸æ˜¯ç›´æ¥ä¼ é€’FileStorageå¯¹è±¡
            file_content = audio_file.read()

            # ä½¿ç”¨io.BytesIOåˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç±»å¯¹è±¡
            import io
            file_data = io.BytesIO(file_content)
            file_data.name = audio_file.filename  # è®¾ç½®æ–‡ä»¶å

            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=file_data
            )
            return response.text
        except Exception as e:
            print(f"éŸ³é¢‘è½¬æ–‡å­—é”™è¯¯: {str(e)}")
            raise

    @staticmethod
    def get_chat_response(messages):
        """
        ä½¿ç”¨OpenAI Chat APIè·å–å›å¤

        å‚æ•°:
            messages: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨

        è¿”å›:
            AIçš„å›å¤æ–‡æœ¬
        """
        try:
            response = client.chat.completions.create(
                model="gpt-4-turbo",
                messages=messages
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"è·å–èŠå¤©å›å¤é”™è¯¯: {str(e)}")
            raise

    @staticmethod
    def text_to_speech(text, voice="alloy"):
        """
        ä½¿ç”¨OpenAI TTS APIå°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³

        å‚æ•°:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: è¯­éŸ³ç±»å‹ (alloy, echo, fable, onyx, nova, shimmer)

        è¿”å›:
            éŸ³é¢‘æ•°æ®çš„äºŒè¿›åˆ¶å†…å®¹
        """
        try:
            response = client.audio.speech.create(
                model="tts-1",
                voice=voice,
                input=text
            )
            return response.content
        except Exception as e:
            print(f"æ–‡å­—è½¬è¯­éŸ³é”™è¯¯: {str(e)}")
            raise
